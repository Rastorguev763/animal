from typing import List, Dict, Tuple
import streamlit as st
from megadetector.utils import url_utils
from megadetector.visualization import visualization_utils as vis_utils
from megadetector.detection import run_detector
from PIL import Image
import numpy as np
import torch
import torch.nn.functional as F
from torchvision import transforms
import pandas as pd

# –ü—É—Ç—å –∫ —Ñ–∞–π–ª–∞–º –º–æ–¥–µ–ª–∏ –∏ –∫–ª–∞—Å—Å–æ–≤
CLASSIFICATION_MODEL_PATH = "src/nto_sochi_model.pt"
CLASSES_DICT: Dict[int, str] = pd.read_csv("src/classes.csv").set_index("id")["species"].to_dict()


class ImageClassifier:
    def __init__(self, model_path: str, classes_dict: Dict[int, str]):
        self.model = torch.jit.load(model_path)
        self.classes_dict = classes_dict
        self.preprocess = transforms.Compose(
            [
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                transforms.Normalize(
                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]
                ),
            ]
        )

    def classify(self, image: Image.Image) -> Tuple[int, float]:
        image_tensor = self.preprocess(image).unsqueeze(0)
        predictions = self.model(image_tensor)
        probabilities = F.softmax(predictions, dim=1)
        predicted_class_index = np.argmax(predictions[0].detach().numpy())
        confidence = round(probabilities[0, predicted_class_index].item(), 2)
        return predicted_class_index, confidence


class MegaDetectorApp:
    def __init__(self, classifier: ImageClassifier, detection_model_path: str):
        self.classifier = classifier
        self.detection_model = run_detector.load_detector(detection_model_path)

    def crop_and_classify(self, image: Image.Image, detections: List[Dict]) -> None:
        image_width, image_height = image.size
        for idx, detection in enumerate(detections):
            x, y, w, h = detection["bbox"]
            x1, y1, x2, y2 = (
                int(x * image_width),
                int(y * image_height),
                int((x + w) * image_width),
                int((y + h) * image_height),
            )
            cropped_image = image.crop((x1, y1, x2, y2))
            if cropped_image.size[0] > 0 and cropped_image.size[1] > 0:
                detection["category"], detection["conf"] = self.classifier.classify(
                    cropped_image
                )

    def detect_objects(self, image: Image.Image, threshold: float) -> Tuple[List[Dict], Dict]:
        result: Dict = self.detection_model.generate_detections_one_image(
            image, detection_threshold=threshold
        )
        detections_above_threshold: List[Dict] = [
            d
            for d in result["detections"]
            if d["conf"] > threshold and d["category"] == str(1)
        ]
        self.crop_and_classify(image, detections_above_threshold)
        return detections_above_threshold, result

    def render_detections(self, image: Image.Image, detections: List[Dict]) -> None:
        vis_utils.render_detection_bounding_boxes(
            detections=detections, image=image, label_map=CLASSES_DICT
        )


# –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å Streamlit
st.title("üêæ MegaDetector –ñ–∏–≤–æ—Ç–Ω—ã–µ üêæ")
st.markdown(
    (
        """
–î–æ–±—Ä–æ –ø–æ–∂–∞–ª–æ–≤–∞—Ç—å –≤ **MegaDetector**! –≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –Ω–∞—Ö–æ–¥–∏—Ç—å –∂–∏–≤–æ—Ç–Ω—ã—Ö —Å
–∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –º–æ–¥–µ–ª–∏ MegaDetector.
–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∏–∂–µ, —á—Ç–æ–±—ã –Ω–∞—á–∞—Ç—å.
"""
    )
)

upload_method = st.selectbox(
    "–í—ã–±–µ—Ä–∏—Ç–µ –∏—Å—Ç–æ—á–Ω–∏–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è", ["URL", "–ó–∞–≥—Ä—É–∑–∫–∞ —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞"], index=0
)
threshold = st.slider("–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –ø–æ—Ä–æ–≥ –≤–µ—Ä–æ—è—Ç–Ω–æ—Å—Ç–∏", 0.0, 1.0, 0.2, 0.05)
st.write(f"–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –ø–æ—Ä–æ–≥: {threshold}")

if upload_method == "URL":
    st.subheader("–®–∞–≥ 1: –í–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è")
    image_url = st.text_input("–í–≤–µ–¥–∏—Ç–µ URL", "")
    if not image_url:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ URL –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è.")
    else:
        if st.button("–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ"):
            with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
                temporary_filename = url_utils.download_url(image_url)
                image = vis_utils.load_image(temporary_filename)
                st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏..."):
                # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
                classifier = ImageClassifier(CLASSIFICATION_MODEL_PATH, CLASSES_DICT)
                app = MegaDetectorApp(classifier, "MDV5A")
                detections, _ = app.detect_objects(image, threshold)
                st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(detections)} –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ—Ä–æ–≥–æ–º –≤—ã—à–µ {threshold}")
                app.render_detections(image, detections)
                st.image(image, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π", use_container_width=True)

elif upload_method == "–ó–∞–≥—Ä—É–∑–∫–∞ —Å –∫–æ–º–ø—å—é—Ç–µ—Ä–∞":
    st.subheader("–®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –≤–∞—à–µ–≥–æ –∫–æ–º–ø—å—é—Ç–µ—Ä–∞")
    uploaded_file = st.file_uploader(
        "–í—ã–±–µ—Ä–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", type=["jpg", "jpeg", "png"]
    )
    if uploaded_file is not None:
        with st.spinner("–ó–∞–≥—Ä—É–∑–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è..."):
            image = Image.open(uploaded_file)
            st.image(image, caption="–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ", use_container_width=True)
        with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ –¥–µ—Ç–µ–∫—Ü–∏–∏..."):
            # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            classifier = ImageClassifier(CLASSIFICATION_MODEL_PATH, CLASSES_DICT)
            app = MegaDetectorApp(classifier, "MDV5A")
            detections, _ = app.detect_objects(image, threshold)
            st.write(f"–ù–∞–π–¥–µ–Ω–æ {len(detections)} –æ–±—ä–µ–∫—Ç–æ–≤ —Å –ø–æ—Ä–æ–≥–æ–º –≤—ã—à–µ {threshold}")
            app.render_detections(image, detections)
            st.image(image, caption="–ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —Å –¥–µ—Ç–µ–∫—Ü–∏–µ–π", use_container_width=True)
